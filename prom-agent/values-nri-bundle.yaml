newrelic-infrastructure:
  # newrelic-infrastructure.enabled -- Install the [`newrelic-infrastructure` chart](https://github.com/newrelic/nri-kubernetes/tree/main/charts/newrelic-infrastructure)
  enabled: true

nri-prometheus:
  # nri-prometheus.enabled -- Install the [`nri-prometheus` chart](https://github.com/newrelic/nri-prometheus/tree/main/charts/nri-prometheus)
  enabled: false

nri-metadata-injection:
  # nri-metadata-injection.enabled -- Install the [`nri-metadata-injection` chart](https://github.com/newrelic/k8s-metadata-injection/tree/main/charts/nri-metadata-injection)
  enabled: true

kube-state-metrics:
  # kube-state-metrics.enabled -- Install the [`kube-state-metrics` chart](https://github.com/kubernetes/kube-state-metrics/tree/master/charts/kube-state-metrics) from the stable helm charts repository.
  # This is mandatory if `infrastructure.enabled` is set to `true` and the user does not provide its own instance of KSM version >=1.8 and <=2.0
  enabled: true

nri-kube-events:
  # nri-kube-events.enabled -- Install the [`nri-kube-events` chart](https://github.com/newrelic/nri-kube-events/tree/main/charts/nri-kube-events)
  enabled: true

newrelic-logging:
  # newrelic-logging.enabled -- Install the [`newrelic-logging` chart](https://github.com/newrelic/helm-charts/tree/master/charts/newrelic-logging)
  enabled: true

newrelic-pixie:
  # newrelic-pixie.enabled -- Install the [`newrelic-pixie`](https://github.com/newrelic/helm-charts/tree/master/charts/newrelic-pixie)
  enabled: false

pixie-chart:
  # pixie-chart.enabled -- Install the [`pixie-chart` chart](https://docs.pixielabs.ai/installing-pixie/install-schemes/helm/#3.-deploy)
  enabled: false

newrelic-infra-operator:
  # newrelic-infra-operator.enabled -- Install the [`newrelic-infra-operator` chart](https://github.com/newrelic/newrelic-infra-operator/tree/main/charts/newrelic-infra-operator) (Beta)
  enabled: false

newrelic-prometheus-agent:
  # newrelic-prometheus-agent.enabled -- Install the [`newrelic-prometheus-agent` chart](https://github.com/newrelic/newrelic-prometheus-configurator/tree/main/charts/newrelic-prometheus-agent)
  enabled: true
  fullnameOverride: "newrelic-prometheus-agent"
  config:
    common:
      scrape_interval: 30s
    newrelic_remote_write:
      extra_write_relabel_configs:
        # Enable the extra_write_relabel_configs below for backwards compatibility with legacy POMI labels.
        # This helpful when migrating from POMI to ensure that Prometheus metrics will contain both labels (e.g. cluster_name and clusterName).
        # For more migration info, please visit the [migration guide](https://docs.newrelic.com/docs/infrastructure/prometheus-integrations/install-configure-prometheus-agent/migration-guide/).
        - source_labels: [namespace]
          action: replace
          target_label: namespaceName
        - source_labels: [node]
          action: replace
          target_label: nodeName
        - source_labels: [pod]
          action: replace
          target_label: podName
        - source_labels: [service]
          action: replace
          target_label: serviceName
        - source_labels: [cluster_name]
          action: replace
          target_label: clusterName
        - source_labels: [job]
          action: replace
          target_label: scrapedTargetKind
        - source_labels: [instance]
          action: replace
          target_label: scrapedTargetInstance

    kubernetes:
      integrations_filter:
        # INSTRUQT: Challenge 2
        enabled: true
        # -- source_labels used to fetch label values in the relabel config added by the integration filters configuration
        source_labels: ["app.kubernetes.io/name", "app.newrelic.io/name", "k8s-app"]
        # -- app_values used to create the regex used in the relabel config added by the integration filters configuration.
        # Note that a single regex will be created from this list, example: '.*(?i)(app1|app2|app3).*'
        app_values: ["redis", "traefik", "calico", "nginx", "coredns", "kube-dns", "etcd", "cockroachdb"]

      # Kubernetes jobs define [kubernetes_sd_configs](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#kubernetes_sd_config)
      # to discover and scrape Kubernetes objects. Besides, a set of relabel_configs are included in order to include some Kubernetes metadata as
      # Labels. For example, address, metrics_path, URL scheme, prometheus_io_parameters, namespace, pod name, service name and labels are taken
      # to set the corresponding labels.
      # Please note, the relabeling allows configuring the pod/endpoints scrape using the following annotations:
      # - `prometheus.io/scheme`: If the metrics endpoint is secured then you will need to set this to `https`
      # - `prometheus.io/path`: If the metrics path is not `/metrics` override this.
      # - `prometheus.io/port`: If the metrics are exposed on a different port to the service for service endpoints or to
      #   the default 9102 for pods.
      # - `prometheus.io/param_<param-name>`: To include additional parameters in the scrape URL.
      jobs:
      # INSTRUQT: Challenge 2
      # 'default' scrapes all targets having 'prometheus.io/scrape: true'
      # out of the box, since kubernetes.integrations_filter.enabled=true then only targets selected by the integration filters are considered.
      - job_name_prefix: default
        target_discovery:
          pod: true
          endpoints: true
          filter:
            annotations:
              prometheus.io/scrape: true

      # INSTRUQT: Challenge 3
      # 'newrelic' scrapes all targets having 'newrelic.io/scrape: true'.
      # This is useful to extend the targets scraped by the 'default' job allowlisting services leveraging `newrelic.io/scrape` annotation
      - job_name_prefix: newrelic
        integrations_filter:
          enabled: false
        target_discovery:
          pod: true
          endpoints: true
          filter:
            annotations:
              newrelic.io/scrape: true

    static_targets:
      jobs:
      # # INSTRUQT: Challenge 4
      # - job_name: instruqt-node-exporter
      #   targets:
      #     - "INSTRUQT_HOSTNAME:9100"
      #   basic_auth:
      #     username: prometheus
      #     password: PASSWORD
      # # INSTRUQT: Challenge 5
      #   extra_metric_relabel_config:
      #     # Drop all metrics in the node_sockstat and node_timex metric groups
      #     - source_labels: [__name__]
      #       regex: node_(sockstat|timex).*
      #       action: drop
      #     # Drop all devices except ens4 and cni0 for all node_network metrics
      #     - source_labels: [__name__, device]
      #       regex: node_network.*;(ens4|cni0)
      #       action: keep

      - job_name: self-metrics
        skip_sharding: true  # sharding is skipped to obtain self-metrics from all Prometheus servers.
        targets:
          - "localhost:9090"
        extra_metric_relabel_config:
          - source_labels: [__name__]
            regex: "\
              prometheus_agent_active_series|\
              prometheus_target_interval_length_seconds|\
              prometheus_target_scrape_pool_targets|\
              prometheus_remote_storage_samples_pending|\
              prometheus_remote_storage_samples_in_total|\
              prometheus_remote_storage_samples_retried_total|\
              prometheus_agent_corruptions_total|\
              prometheus_remote_storage_shards|\
              prometheus_sd_kubernetes_events_total|\
              prometheus_agent_checkpoint_creations_failed_total|\
              prometheus_agent_checkpoint_deletions_failed_total|\
              prometheus_remote_storage_samples_dropped_total|\
              prometheus_remote_storage_samples_failed_total|\
              prometheus_sd_kubernetes_http_request_total|\
              prometheus_agent_truncate_duration_seconds_sum|\
              prometheus_build_info|\
              process_resident_memory_bytes|\
              process_virtual_memory_bytes|\
              process_cpu_seconds_total"
            action: keep

newrelic-k8s-metrics-adapter:
  # newrelic-k8s-metrics-adapter.enabled -- Install the [`newrelic-k8s-metrics-adapter.` chart](https://github.com/newrelic/newrelic-k8s-metrics-adapter/tree/main/charts/newrelic-k8s-metrics-adapter) (Beta)
  enabled: false


# -- change the behaviour globally to all the supported helm charts.
# See [user's guide of the common library](https://github.com/newrelic/helm-charts/blob/master/library/common-library/README.md) for further information.
# @default -- See [`values.yaml`](values.yaml)
global:
  # -- The cluster name for the Kubernetes cluster.
  cluster: "instruqt-cluster"

  # -- The license key for your New Relic Account. This will be preferred configuration option if both `licenseKey` and `customSecret` are specified.
  licenseKey: ""
  # -- The license key for your New Relic Account. This will be preferred configuration option if both `insightsKey` and `customSecret` are specified.
  insightsKey: ""
  # -- Name of the Secret object where the license key is stored
  customSecretName: "newrelic-license-key"
  # -- Key in the Secret object where the license key is stored
  customSecretLicenseKey: "license-key"

  # -- Additional labels for chart objects
  labels: {}
  # -- Additional labels for chart pods
  podLabels: {}

  images:
    # -- Changes the registry where to get the images. Useful when there is an internal image cache/proxy
    registry: ""
    # -- Set secrets to be able to fetch images
    pullSecrets: []

  serviceAccount:
    # -- Add these annotations to the service account we create
    annotations: {}
    # -- Configures if the service account should be created or not
    create:
    # -- Change the name of the service account. This is honored if you disable on this chart the creation of the service account so you can use your own
    name:

  # -- (bool) Sets pod's hostNetwork
  # @default -- false
  hostNetwork:
  # -- Sets pod's dnsConfig
  dnsConfig: {}

  # -- Sets pod's priorityClassName
  priorityClassName: ""
  # -- Sets security context (at pod level)
  podSecurityContext: {}
  # -- Sets security context (at container level)
  containerSecurityContext: {}

  # -- Sets pod/node affinities
  affinity: {}
  # -- Sets pod's node selector
  nodeSelector: {}
  # -- Sets pod's tolerations to node taints
  tolerations: []

  # -- Adds extra attributes to the cluster and all the metrics emitted to the backend
  customAttributes: {}

  # -- (bool) Reduces number of metrics sent in order to reduce costs
  # @default -- false
  lowDataMode:

  # -- (bool) In each integration it has different behavior. See [Further information](#values-managed-globally-3) but all aims to send less metrics to the backend to try to save costs |
  # @default -- false
  privileged:

  # -- (bool) Must be set to `true` when deploying in an EKS Fargate environment
  # @default -- false
  fargate:

  # -- Configures the integration to send all HTTP/HTTPS request through the proxy in that URL. The URL should have a standard format like `https://user:password@hostname:port`
  proxy: ""

  # -- (bool) Send the metrics to the staging backend. Requires a valid staging license key
  # @default -- false
  nrStaging:
  fedramp:
    # fedramp.enabled -- (bool) Enables FedRAMP
    # @default -- false
    enabled:

  # -- (bool) Sets the debug logs to this integration or all integrations if it is set globally
  # @default -- false
  verboseLog:


# To add values to the subcharts. Follow Helm's guide: https://helm.sh/docs/chart_template_guide/subcharts_and_globals

# If you wish to monitor services running on Kubernetes you can provide integrations
# configuration under `integrations_config` that it will passed down to the `newrelic-infrastructure` chart.
#
# You just need to create a new entry where the "name" is the filename of the configuration file and the data is the content of
# the integration configuration. The name must end in ".yaml" as this will be the
# filename generated and the Infrastructure agent only looks for YAML files.
#
# The data part is the actual integration configuration as described in the spec here:
# https://docs.newrelic.com/docs/integrations/integrations-sdk/file-specifications/integration-configuration-file-specifications-agent-v180
#
# In the following example you can see how to monitor a Redis integration with autodiscovery
#
#
# newrelic-infrastructure:
#   integrations:
#     nri-redis-sampleapp:
#       discovery:
#         command:
#           exec: /var/db/newrelic-infra/nri-discovery-kubernetes --tls --port 10250
#           match:
#             label.app: sampleapp
#       integrations:
#         - name: nri-redis
#           env:
#             # using the discovered IP as the hostname address
#             HOSTNAME: ${discovery.ip}
#             PORT: 6379
#           labels:
#             env: test